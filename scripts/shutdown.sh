#!/usr/bin/env bash
# =============================================================================
# Shutdown -- Scale ALL node groups to 0
#
# Scales both the GPU and CPU EKS node groups to 0 desired instances,
# terminating all EC2 instances and stopping billing.
#
# What happens when nodes scale to 0:
#   - All pods go to Pending (no nodes to run on)
#   - EBS PVCs detach but are NOT deleted (data persists)
#   - The EKS control plane stays running (~$0.10/hr -- AWS charges for
#     the control plane regardless of node count)
#   - When nodes scale back up (via startup.sh), pods auto-reschedule
#     and PVCs reattach
#
# IMPORTANT: Always run this when done for the day!
#
# Usage: ./scripts/shutdown.sh
# =============================================================================
set -euo pipefail

CLUSTER_NAME="${CLUSTER_NAME:-pdf-rag-chatbot}"
AWS_REGION="${AWS_REGION:-us-east-1}"

# -----------------------------------------------------------------------
# Node group names are auto-generated by Terraform with a timestamp
# suffix. Rather than hardcoding, we look them up dynamically using
# the AWS CLI. This way the script works even after Terraform recreates
# a node group (which changes the name).
# -----------------------------------------------------------------------
# -----------------------------------------------------------------------
# Kill any active kubectl port-forward processes for this namespace.
# Once nodes scale to 0, port-forwards become stale connections that
# hang around until manually killed. Cleaning them up here avoids
# confusing "connection refused" errors later.
# -----------------------------------------------------------------------
echo ">>> Cleaning up port-forward processes..."
PF_PIDS=$(pgrep -f "port-forward.*pdf-rag-chatbot" 2>/dev/null || true)
if [ -n "${PF_PIDS}" ]; then
  echo "${PF_PIDS}" | xargs kill 2>/dev/null || true
  echo "Stopped port-forward PIDs: ${PF_PIDS}"
else
  echo "No active port-forwards found."
fi
echo ""

echo "=== Shutting Down All Nodes ==="
echo "Cluster: ${CLUSTER_NAME}"
echo "Region:  ${AWS_REGION}"
echo ""

echo ">>> Looking up node group names..."
NODEGROUPS=$(aws eks list-nodegroups \
  --cluster-name "${CLUSTER_NAME}" \
  --region "${AWS_REGION}" \
  --query 'nodegroups[]' \
  --output text)

if [ -z "${NODEGROUPS}" ]; then
  echo "No node groups found. Nothing to shut down."
  exit 0
fi

echo "Found node groups: ${NODEGROUPS}"
echo ""

# -----------------------------------------------------------------------
# Scale each node group to 0. We determine maxSize from the node group
# name prefix: GPU nodes max at 1, CPU nodes max at 2.
# -----------------------------------------------------------------------
for NG in ${NODEGROUPS}; do
  if [[ "${NG}" == gpu_nodes* ]]; then
    MAX_SIZE=1
  else
    MAX_SIZE=2
  fi

  echo ">>> Scaling ${NG} to 0 (maxSize=${MAX_SIZE})..."
  aws eks update-nodegroup-config \
    --cluster-name "${CLUSTER_NAME}" \
    --nodegroup-name "${NG}" \
    --scaling-config minSize=0,maxSize="${MAX_SIZE}",desiredSize=0 \
    --region "${AWS_REGION}" \
    --query 'update.status' \
    --output text
  echo ""
done

echo "=== All node groups scaling to 0 ==="
echo ""
echo "Instances will terminate in ~60 seconds."
echo "EKS control plane remains running (~\$0.10/hr)."
echo "PVCs (Qdrant data, PostgreSQL) are preserved."
echo ""
echo "To start back up: ./scripts/startup.sh"
